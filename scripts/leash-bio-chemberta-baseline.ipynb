{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Update\n","|version|update|cv|lb|\n","|:--|:--|--:|--:|\n","|v3|-|-|0.343|\n","|v4|increase N_ROWS from 90M to 180M|0.573|0.465|\n","|v5|increase N_SAMPLES from 1M to 2M<br>change to a larger model (5M -> 10M)|0.622|0.486|\n","|v8|Add normalization commented by [@hengck23](https://www.kaggle.com/hengck23)|0.629|0.496|"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rdkit in /opt/conda/lib/python3.10/site-packages (2023.9.6)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rdkit) (1.26.4)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit) (9.5.0)\n"]}],"source":["!pip install rdkit"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-23T04:24:15.846535Z","iopub.status.busy":"2024-04-23T04:24:15.846197Z","iopub.status.idle":"2024-04-23T04:24:45.658021Z","shell.execute_reply":"2024-04-23T04:24:45.657007Z","shell.execute_reply.started":"2024-04-23T04:24:15.846507Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing /root/program/leash/data/package/lightning-2.2.1-py3-none-any.whl\n","Requirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning==2.2.1) (6.0.1)\n","Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning==2.2.1) (2024.3.1)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.2.1) (0.11.2)\n","Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning==2.2.1) (1.26.4)\n","Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.2.1) (21.3)\n","Requirement already satisfied: torch<4.0,>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.2.1) (2.1.2)\n","Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.2.1) (1.4.0.post0)\n","Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.2.1) (4.66.4)\n","Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning==2.2.1) (4.9.0)\n","Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning==2.2.1) (2.2.5)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning==2.2.1) (3.9.1)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning==2.2.1) (69.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning==2.2.1) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning==2.2.1) (3.13.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning==2.2.1) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning==2.2.1) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning==2.2.1) (3.1.2)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.2.1) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.2.1) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.2.1) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.2.1) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.2.1) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.2.1) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=1.13.0->lightning==2.2.1) (2.1.3)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.13.0->lightning==2.2.1) (1.3.0)\n","Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.2.1) (3.6)\n","lightning is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"]}],"source":["!pip install -U ../data/package/lightning-2.2.1-py3-none-any.whl"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:24:45.660942Z","iopub.status.busy":"2024-04-23T04:24:45.660443Z","iopub.status.idle":"2024-04-23T04:25:04.515527Z","shell.execute_reply":"2024-04-23T04:25:04.514518Z","shell.execute_reply.started":"2024-04-23T04:24:45.6609Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-05 09:04:18.658782: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-06-05 09:04:18.687251: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-05 09:04:18.687273: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-05 09:04:18.688049: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-05 09:04:18.694110: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["from pathlib import Path\n","\n","import numpy as np\n","import polars as pl\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchmetrics import AveragePrecision\n","import lightning as L\n","from lightning.pytorch.callbacks import (\n","    EarlyStopping,\n","    ModelCheckpoint,\n","    TQDMProgressBar,\n",")\n","from transformers import AutoConfig, AutoTokenizer, AutoModel, DataCollatorWithPadding\n","import datasets\n","from rdkit import Chem"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["class Config:\n","    PREPROCESS = False\n","    KAGGLE_NOTEBOOK = False\n","    DEBUG = True\n","    \n","  \n","    \n","    \n","if Config.DEBUG:\n","    n_rows = 10**4\n","else:\n","    n_rows = None\n","    "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["if Config.KAGGLE_NOTEBOOK:\n","    RAW_DIR = \"/kaggle/input/leash-BELKA/\"\n","    PROCESSED_DIR = \"/kaggle/input/belka-enc-dataset\"\n","    OUTPUT_DIR = \"\"\n","    MODEL_DIR = \"\"\n","else:\n","    RAW_DIR = \"../data/raw/\"\n","    PROCESSED_DIR = \"../data/processed/\"\n","    OUTPUT_DIR = \"../data/result/\"\n","    MODEL_DIR = \"../models/\"\n","\n","TRAIN_DATA_NAME = \"local_train_enc.parquet\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:25:04.527734Z","iopub.status.busy":"2024-04-23T04:25:04.527498Z","iopub.status.idle":"2024-04-23T04:25:04.576448Z","shell.execute_reply":"2024-04-23T04:25:04.575524Z","shell.execute_reply.started":"2024-04-23T04:25:04.527713Z"},"trusted":true},"outputs":[],"source":["DEBUG = True\n","NORMALIZE = True\n","N_ROWS = 180_000_000\n","assert N_ROWS is None or N_ROWS % 3 == 0\n","if DEBUG:\n","    N_SAMPLES = 10_000\n","else:\n","    N_SAMPLES = 2_000_000\n","PROTEIN_NAMES = [\"BRD4\", \"HSA\", \"sEH\"]\n","data_dir = Path(RAW_DIR)\n","model_name = \"DeepChem/ChemBERTa-10M-MTR\"\n","batch_size = 256\n","trainer_params = {\n","  \"max_epochs\": 5,\n","  \"enable_progress_bar\": True,\n","  \"accelerator\": \"auto\",\n","  \"precision\": \"16-mixed\",\n","  \"gradient_clip_val\": None,\n","  \"accumulate_grad_batches\": 1,\n","  \"devices\": [0],\n","}\n","\n","TRAIN_DATA_NAME = \"local_train.parquet\"\n"]},{"cell_type":"markdown","metadata":{},"source":["# Prepare Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:25:04.577955Z","iopub.status.busy":"2024-04-23T04:25:04.577621Z","iopub.status.idle":"2024-04-23T04:25:26.148615Z","shell.execute_reply":"2024-04-23T04:25:26.14708Z","shell.execute_reply.started":"2024-04-23T04:25:04.57792Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>molecule_smiles</th><th>protein_name</th><th>binds</th></tr><tr><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;O=C(N[Dy])c1cnn(-c2ccc(F)cc2)c…</td><td>&quot;BRD4&quot;</td><td>0</td></tr><tr><td>&quot;Cc1csc(Nc2nc(Nc3ncco3)nc(N[C@@…</td><td>&quot;sEH&quot;</td><td>0</td></tr><tr><td>&quot;COC(=O)c1ccc(Nc2nc(NCc3cccc(C(…</td><td>&quot;BRD4&quot;</td><td>0</td></tr><tr><td>&quot;Cc1cc(F)ncc1CNc1nc(Nc2nc3ncc(C…</td><td>&quot;BRD4&quot;</td><td>0</td></tr><tr><td>&quot;C=CCC(CC=C)(Nc1nc(NCC(C)S(C)=O…</td><td>&quot;BRD4&quot;</td><td>0</td></tr></tbody></table></div>"],"text/plain":["shape: (5, 3)\n","┌─────────────────────────────────┬──────────────┬───────┐\n","│ molecule_smiles                 ┆ protein_name ┆ binds │\n","│ ---                             ┆ ---          ┆ ---   │\n","│ str                             ┆ str          ┆ i64   │\n","╞═════════════════════════════════╪══════════════╪═══════╡\n","│ O=C(N[Dy])c1cnn(-c2ccc(F)cc2)c… ┆ BRD4         ┆ 0     │\n","│ Cc1csc(Nc2nc(Nc3ncco3)nc(N[C@@… ┆ sEH          ┆ 0     │\n","│ COC(=O)c1ccc(Nc2nc(NCc3cccc(C(… ┆ BRD4         ┆ 0     │\n","│ Cc1cc(F)ncc1CNc1nc(Nc2nc3ncc(C… ┆ BRD4         ┆ 0     │\n","│ C=CCC(CC=C)(Nc1nc(NCC(C)S(C)=O… ┆ BRD4         ┆ 0     │\n","└─────────────────────────────────┴──────────────┴───────┘"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df = pl.read_parquet(\n","    Path(PROCESSED_DIR, TRAIN_DATA_NAME),\n","    columns=[\"molecule_smiles\", \"protein_name\", \"binds\"],\n","    n_rows=N_ROWS,\n",")\n","test_df = pl.read_parquet(\n","    Path(RAW_DIR, \"test.parquet\"),\n","    columns=[\"molecule_smiles\"],\n","    n_rows=10000 if DEBUG else None,\n",")\n","\n","df.head()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:25:26.151356Z","iopub.status.busy":"2024-04-23T04:25:26.150882Z","iopub.status.idle":"2024-04-23T04:25:30.695707Z","shell.execute_reply":"2024-04-23T04:25:30.694373Z","shell.execute_reply.started":"2024-04-23T04:25:26.151308Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["shape: (5, 4)\n","┌─────────────────────────────────┬──────┬─────┬─────┐\n","│ molecule_smiles                 ┆ BRD4 ┆ HSA ┆ sEH │\n","│ ---                             ┆ ---  ┆ --- ┆ --- │\n","│ str                             ┆ i64  ┆ i64 ┆ i64 │\n","╞═════════════════════════════════╪══════╪═════╪═════╡\n","│ CC1(F)CCN(CCNc2nc(NCC3(CO)CC4C… ┆ 0    ┆ 0   ┆ 0   │\n","│ COC(=O)c1c[nH]c(C(=O)OC)c1Nc1n… ┆ 0    ┆ 0   ┆ 0   │\n","│ O=C(N[Dy])c1cnc(Cl)cc1Nc1nc(NC… ┆ 0    ┆ 0   ┆ 0   │\n","│ O=C(N[Dy])[C@H](Cc1ccsc1)Nc1nc… ┆ 0    ┆ 0   ┆ 0   │\n","│ O=C(N[Dy])[C@H](Cc1ccc(C(F)(F)… ┆ 0    ┆ 0   ┆ 0   │\n","└─────────────────────────────────┴──────┴─────┴─────┘\n","shape: (1, 3)\n","┌──────┬─────┬─────┐\n","│ BRD4 ┆ HSA ┆ sEH │\n","│ ---  ┆ --- ┆ --- │\n","│ i64  ┆ i64 ┆ i64 │\n","╞══════╪═════╪═════╡\n","│ 65   ┆ 51  ┆ 54  │\n","└──────┴─────┴─────┘\n"]}],"source":["dfs = []\n","for i, protein_name in enumerate(PROTEIN_NAMES):\n","    sub_df = df[i::3]\n","    sub_df = sub_df.rename({\"binds\": protein_name})\n","    if i == 0:\n","        dfs.append(sub_df.drop([\"id\", \"protein_name\"]))\n","    else:\n","        dfs.append(sub_df[[protein_name]])\n","df = pl.concat(dfs, how=\"horizontal\")\n","df = df.sample(n=N_SAMPLES)\n","print(df.head())\n","print(df[PROTEIN_NAMES].sum())"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:25:45.397457Z","iopub.status.busy":"2024-04-23T04:25:45.397079Z","iopub.status.idle":"2024-04-23T04:25:56.554365Z","shell.execute_reply":"2024-04-23T04:25:56.553318Z","shell.execute_reply.started":"2024-04-23T04:25:45.397427Z"},"trusted":true},"outputs":[],"source":["def normalize(x):\n","    mol = Chem.MolFromSmiles(x)\n","    smiles = Chem.MolToSmiles(mol, canonical=True, isomericSmiles=False)\n","    return smiles\n","\n","\n","if NORMALIZE:\n","    df = df.with_columns(pl.col(\"molecule_smiles\").map_elements(normalize, return_dtype=pl.Utf8))\n","    test_df = test_df.with_columns(pl.col(\"molecule_smiles\").map_elements(normalize, return_dtype=pl.Utf8))"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:25:56.557089Z","iopub.status.busy":"2024-04-23T04:25:56.556369Z","iopub.status.idle":"2024-04-23T04:25:56.572576Z","shell.execute_reply":"2024-04-23T04:25:56.571714Z","shell.execute_reply.started":"2024-04-23T04:25:56.557053Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(8000, 2000)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["train_idx, val_idx = train_test_split(np.arange(len(df)), test_size=0.2)\n","train_df, val_df = df[train_idx], df[val_idx]\n","len(train_df), len(val_df)"]},{"cell_type":"markdown","metadata":{},"source":["# Build Dataset"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:25:56.574117Z","iopub.status.busy":"2024-04-23T04:25:56.573763Z","iopub.status.idle":"2024-04-23T04:25:58.251181Z","shell.execute_reply":"2024-04-23T04:25:58.250422Z","shell.execute_reply.started":"2024-04-23T04:25:56.574084Z"},"trusted":true},"outputs":[],"source":["# tokenizer とは、テキストデータを機械学習モデルが理解できる形式に変換するためのツールです。具体的には、文章を単語やサブワードに分割し、それぞれを数値化する役割を果たします。\n","# 今回はChemBERTa使用\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:25:58.253574Z","iopub.status.busy":"2024-04-23T04:25:58.253277Z","iopub.status.idle":"2024-04-23T04:25:58.391622Z","shell.execute_reply":"2024-04-23T04:25:58.390766Z","shell.execute_reply.started":"2024-04-23T04:25:58.253549Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9f6887fafe340b5826b71f249734149","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'input_ids': array([12, 16, 15, 20, 15, 15, 17, 23, 15, 21, 25, 15, 17, 23, 16, 15, 26,\n","        15, 15, 17, 54, 18, 15, 15, 32, 15, 15, 15, 25, 15, 26, 32, 18, 25,\n","        15, 17, 23, 15, 26, 25, 15, 15, 17, 54, 18, 15, 15, 26, 16, 17, 22,\n","        19, 18, 23, 18, 25, 21, 18, 25, 17, 31, 15, 21, 15, 15, 15, 15, 15,\n","        21, 18, 25, 20, 13], dtype=int32),\n"," 'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1], dtype=int8),\n"," 'label': array([0, 0, 0])}"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["def tokenize(batch, tokenizer):\n","    output = tokenizer(batch[\"molecule_smiles\"], truncation=True)\n","    return output\n","\n","\n","class LMDataset(Dataset):\n","    def __init__(self, df, tokenizer, stage=\"train\"):\n","        assert stage in [\"train\", \"val\", \"test\"]\n","        self.tokenizer = tokenizer\n","        self.stage = stage\n","        df = (\n","            datasets.Dataset\n","            .from_pandas(df.to_pandas())\n","            .map(tokenize, batched=True, fn_kwargs={\"tokenizer\": self.tokenizer})\n","            .to_pandas()\n","        )\n","        self.df = pl.from_pandas(df)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        data = self._generate_data(index)\n","        data[\"label\"] = self._generate_label(index)\n","        return data        \n","\n","    def _generate_data(self, index):\n","        data = {\n","            \"input_ids\": np.array(self.df[index, \"input_ids\"]),\n","            \"attention_mask\": np.array(self.df[index, \"attention_mask\"]),\n","        }\n","        return data\n","    \n","    def _generate_label(self, index):\n","        if self.stage == \"test\":\n","            return np.array([0, 0, 0])\n","        else:\n","            return self.df[index, PROTEIN_NAMES].to_numpy()[0]\n","\n","\n","LMDataset(train_df[:100], tokenizer)[0]\n","\n","# input_ids: トークン化されたSMILEのID．もとのSMILES表記がそれぞれのトークンに分割され、それらがIDに変換された結果です\n","# attention_mask: トークンがパディングされているかどうかを示すマスクです．パディングされている場合は0，それ以外は1です．\n","# label: 3つのターゲットのバインディング情報です．\n"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:25:58.393295Z","iopub.status.busy":"2024-04-23T04:25:58.392778Z","iopub.status.idle":"2024-04-23T04:25:58.403132Z","shell.execute_reply":"2024-04-23T04:25:58.402272Z","shell.execute_reply.started":"2024-04-23T04:25:58.393267Z"},"trusted":true},"outputs":[],"source":["class LBDataModule(L.LightningDataModule):\n","    def __init__(self, train_df, val_df, test_df, tokenizer):\n","        super().__init__()\n","        self.train_df = train_df\n","        self.val_df = val_df\n","        self.test_df = test_df\n","        self.tokenizer = tokenizer\n","\n","    def _generate_dataset(self, stage):\n","        if stage == \"train\":\n","            df = self.train_df\n","        elif stage == \"val\":\n","            df = self.val_df\n","        elif stage == \"test\":\n","            df = self.test_df\n","        else:\n","            raise NotImplementedError\n","        dataset = LMDataset(df, self.tokenizer, stage=stage)\n","        return dataset\n","\n","    def _generate_dataloader(self, stage):\n","        dataset = self._generate_dataset(stage)\n","        if stage == \"train\":\n","            shuffle=True\n","            drop_last=True\n","        else:\n","            shuffle=False\n","            drop_last=False\n","        return DataLoader(\n","            dataset,\n","            batch_size=batch_size,\n","            shuffle=shuffle,\n","            drop_last=drop_last,\n","            pin_memory=True,\n","            collate_fn=DataCollatorWithPadding(self.tokenizer),\n","        )\n","\n","    def train_dataloader(self):\n","        return self._generate_dataloader(\"train\")\n","\n","    def val_dataloader(self):\n","        return self._generate_dataloader(\"val\")\n","\n","    def test_dataloader(self):\n","        return self._generate_dataloader(\"test\")\n","    \n","    def local_test_dataloader(self, local_test_df):\n","        dataset = LMDataset(local_test_df, self.tokenizer, stage=\"test\")\n","        return DataLoader(\n","            dataset,\n","            batch_size=batch_size,\n","            shuffle=False,\n","            drop_last=False,\n","            pin_memory=True,\n","            collate_fn=DataCollatorWithPadding(self.tokenizer),\n","        )\n","    \n","    \n","datamodule = LBDataModule(train_df, val_df, test_df, tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["# Build Model"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:25:58.405462Z","iopub.status.busy":"2024-04-23T04:25:58.404562Z","iopub.status.idle":"2024-04-23T04:26:00.282165Z","shell.execute_reply":"2024-04-23T04:26:00.281185Z","shell.execute_reply.started":"2024-04-23T04:25:58.405433Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]},{"data":{"text/plain":["LMModel(\n","  (lm): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(600, 384, padding_idx=1)\n","      (position_embeddings): Embedding(515, 384, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 384)\n","      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.144, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-2): 3 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=384, out_features=384, bias=True)\n","              (key): Linear(in_features=384, out_features=384, bias=True)\n","              (value): Linear(in_features=384, out_features=384, bias=True)\n","              (dropout): Dropout(p=0.109, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=384, out_features=384, bias=True)\n","              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.144, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=384, out_features=464, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=464, out_features=384, bias=True)\n","            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.144, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.144, inplace=False)\n","  (classifier): Linear(in_features=384, out_features=3, bias=True)\n","  (loss_fn): BCEWithLogitsLoss()\n",")"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["class LMModel(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        self.config = AutoConfig.from_pretrained(model_name, num_labels=3)\n","        # hugging faceのtransformersライブラリを使用して、事前学習済みモデルをロード\n","        self.lm = AutoModel.from_pretrained(model_name, add_pooling_layer=False)\n","        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(self.config.hidden_size, self.config.num_labels)\n","        self.loss_fn = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","\n","    def forward(self, batch):\n","        last_hidden_state = self.lm(\n","            batch[\"input_ids\"],\n","            attention_mask=batch[\"attention_mask\"],\n","        ).last_hidden_state\n","        logits = self.classifier(\n","            self.dropout(last_hidden_state[:, 0])\n","        )\n","        return {\n","            \"logits\": logits,\n","        }\n","\n","    def calculate_loss(self, batch):\n","        output = self.forward(batch)\n","        loss = self.loss_fn(output[\"logits\"], batch[\"labels\"].float())\n","        output[\"loss\"] = loss\n","        return output\n","\n","    \n","LMModel(model_name)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:26:00.283955Z","iopub.status.busy":"2024-04-23T04:26:00.283579Z","iopub.status.idle":"2024-04-23T04:26:00.503138Z","shell.execute_reply":"2024-04-23T04:26:00.502326Z","shell.execute_reply.started":"2024-04-23T04:26:00.283921Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["class LBModelModule(L.LightningModule):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        self.model = LMModel(model_name)\n","        self.map = AveragePrecision(task=\"binary\")\n","\n","    def forward(self, batch):\n","        return self.model(batch)\n","\n","    def calculate_loss(self, batch, batch_idx):\n","        return self.model.calculate_loss(batch)\n","\n","    def training_step(self, batch, batch_idx):\n","        ret = self.calculate_loss(batch, batch_idx)\n","        self.log(\"train_loss\", ret[\"loss\"], on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)\n","        return ret[\"loss\"]\n","\n","    def validation_step(self, batch, batch_idx):\n","        ret = self.calculate_loss(batch, batch_idx)\n","        self.log(\"val_loss\", ret[\"loss\"], on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n","        self.map.update(F.sigmoid(ret[\"logits\"]), batch[\"labels\"].long())\n","\n","    def on_validation_epoch_end(self):\n","        val_map = self.map.compute()\n","        self.log(\"val_map\", val_map, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n","        self.map.reset()\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n","        logits = self.forward(batch)[\"logits\"]\n","        probs = F.sigmoid(logits)\n","        return probs\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n","        return {\n","            \"optimizer\": optimizer,\n","        }\n","\n","    \n","modelmodule = LBModelModule(model_name)"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:26:00.504604Z","iopub.status.busy":"2024-04-23T04:26:00.504302Z","iopub.status.idle":"2024-04-23T04:26:00.51983Z","shell.execute_reply":"2024-04-23T04:26:00.518947Z","shell.execute_reply.started":"2024-04-23T04:26:00.504578Z"},"trusted":true},"outputs":[],"source":["checkpoint_callback = ModelCheckpoint(\n","    filename=f\"model-{{val_map:.4f}}\",\n","    save_weights_only=True,\n","    monitor=\"val_map\",\n","    mode=\"max\",\n","    dirpath=MODEL_DIR,\n","    save_top_k=1,\n","    verbose=1,\n",")\n","early_stop_callback = EarlyStopping(monitor=\"val_map\", mode=\"max\", patience=3)\n","progress_bar_callback = TQDMProgressBar(refresh_rate=1)\n","callbacks = [\n","    checkpoint_callback,\n","    early_stop_callback,\n","    progress_bar_callback,\n","]"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:26:00.52124Z","iopub.status.busy":"2024-04-23T04:26:00.520963Z","iopub.status.idle":"2024-04-23T04:26:44.805119Z","shell.execute_reply":"2024-04-23T04:26:44.804095Z","shell.execute_reply.started":"2024-04-23T04:26:00.521217Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO: IPU available: False, using: 0 IPUs\n","INFO: HPU available: False, using: 0 HPUs\n","/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:215: UserWarning: \n","NVIDIA H100 PCIe with CUDA capability sm_90 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_60 sm_70 sm_75 compute_70 compute_75.\n","If you want to use the NVIDIA H100 PCIe GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(\n","INFO: You are using a CUDA device ('NVIDIA H100 PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:653: Checkpoint directory /root/program/leash/models exists and is not empty.\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name  | Type                   | Params\n","-------------------------------------------------\n","0 | model | LMModel                | 3.3 M \n","1 | map   | BinaryAveragePrecision | 0     \n","-------------------------------------------------\n","3.3 M     Trainable params\n","0         Non-trainable params\n","3.3 M     Total params\n","13.123    Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69305388232f4f619dc8e33c3b0f294e","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"742da57e89a64b73afa3045238fe5dc1","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e45cb64d87da464e861072122b136c3b","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n","/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (31) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d2321be676f4fd3b293cd3753b1e23f","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b5986bcb11e4023954d56540ca98df8","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO: Epoch 0, global step 31: 'val_map' reached 0.00625 (best 0.00625), saving model to '/root/program/leash/models/model-val_map=0.0063.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0f32416dcfb4c2387e224ddd1fe9c05","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO: Epoch 1, global step 62: 'val_map' reached 0.00740 (best 0.00740), saving model to '/root/program/leash/models/model-val_map=0.0074.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d39dc02ef6b43bca0a524738967fe9a","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO: Epoch 2, global step 93: 'val_map' was not in top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d8b6b65dd2c4cb7a270945e27cb1bf8","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO: Epoch 3, global step 124: 'val_map' reached 0.00956 (best 0.00956), saving model to '/root/program/leash/models/model-val_map=0.0096.ckpt' as top 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11107e1a4e05448c8511793839e45003","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO: Epoch 4, global step 155: 'val_map' was not in top 1\n","INFO: `Trainer.fit` stopped: `max_epochs=5` reached.\n"]}],"source":["trainer = L.Trainer(callbacks=callbacks, **trainer_params)\n","trainer.fit(modelmodule, datamodule)"]},{"cell_type":"markdown","metadata":{},"source":["# Inference"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:26:44.80806Z","iopub.status.busy":"2024-04-23T04:26:44.807748Z","iopub.status.idle":"2024-04-23T04:26:44.818284Z","shell.execute_reply":"2024-04-23T04:26:44.817359Z","shell.execute_reply.started":"2024-04-23T04:26:44.808034Z"},"trusted":true},"outputs":[],"source":["test_df = pl.read_parquet(\n","    Path(data_dir, \"test.parquet\"),\n","    columns=[\"molecule_smiles\"],\n","    n_rows=10000 if DEBUG else None,\n",")"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:26:44.820368Z","iopub.status.busy":"2024-04-23T04:26:44.819691Z","iopub.status.idle":"2024-04-23T04:26:50.404077Z","shell.execute_reply":"2024-04-23T04:26:50.403019Z","shell.execute_reply.started":"2024-04-23T04:26:44.820332Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"177348712eab4f3192da4244f6fcca51","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["../models/model-val_map=0.0946.ckpt\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02ca8e32b1354bbeb009e2b85f90be2f","version_major":2,"version_minor":0},"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_349201/1186736651.py:22: DeprecationWarning: The default coalesce behavior of left join will change to `False` in the next breaking release. Pass `coalesce=True` to keep the current behavior and silence this warning.\n","  pl.read_parquet(Path(data_dir, \"test.parquet\"), columns=[\"id\", \"molecule_smiles\", \"protein_name\"])\n"]},{"name":"stdout","output_type":"stream","text":["../models/model-val_map=0.0363.ckpt\n"]},{"name":"stderr","output_type":"stream","text":["INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3032e356565e440f83ca9638c2c40ecb","version_major":2,"version_minor":0},"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["../models/model-val_map=0.0399.ckpt\n"]},{"name":"stderr","output_type":"stream","text":["INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53ad9302b2a14c4aaf611ab736083e44","version_major":2,"version_minor":0},"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["../models/model-val_map=0.0096.ckpt\n"]},{"name":"stderr","output_type":"stream","text":["INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5d523a52810492f8e10031fb08a3698","version_major":2,"version_minor":0},"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["working_dir = Path(MODEL_DIR)\n","model_paths = working_dir.glob(\"*.ckpt\")\n","test_dataloader = datamodule.test_dataloader()\n","for model_path in model_paths:\n","    print(model_path)\n","    modelmodule = LBModelModule.load_from_checkpoint(\n","        checkpoint_path=model_path,\n","        model_name=model_name,\n","    )\n","    predictions = trainer.predict(modelmodule, test_dataloader)\n","    predictions = torch.cat(predictions).numpy()\n","    pred_dfs = []\n","    for i, protein_name in enumerate(PROTEIN_NAMES):\n","        pred_dfs.append(\n","            test_df.with_columns(\n","                pl.lit(protein_name).alias(\"protein_name\"),\n","                pl.lit(predictions[:, i]).alias(\"binds\"),\n","            )\n","        )\n","    pred_df = pl.concat(pred_dfs)\n","    submit_df = (\n","        pl.read_parquet(Path(data_dir, \"test.parquet\"), columns=[\"id\", \"molecule_smiles\", \"protein_name\"])\n","        .join(pred_df, on=[\"molecule_smiles\", \"protein_name\"], how=\"left\")\n","        .select([\"id\", \"binds\"])\n","        .sort(\"id\")\n","    )\n","    submit_df.write_csv(Path(working_dir, f\"submission_{model_path.stem}.csv\"))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["local_test_df = pl.read_parquet(\n","    Path(PROCESSED_DIR, \"local_test.parquet\"),\n","    columns=[\"molecule_smiles\", \"protein_name\", \"binds\"],\n","    n_rows=10000 if DEBUG else None,\n",")\n","\n","def one_hot_binds(df):\n","    df = df.with_columns([\n","    ((df[\"protein_name\"] == \"BRD4\").cast(pl.Int32) * df[\"binds\"]).alias(\"BRD4\"),\n","    ((df[\"protein_name\"] == \"HSA\").cast(pl.Int32) * df[\"binds\"]).alias(\"HSA\"),\n","    ((df[\"protein_name\"] == \"sEH\").cast(pl.Int32) * df[\"binds\"]).alias(\"sEH\")\n","    ])\n","    df = df.drop([\"binds\", \"protein_name\"])\n","    return df\n","local_test_df = one_hot_binds(local_test_df)\n","\n","\n","target = local_test_df[PROTEIN_NAMES]\n","local_test_df = local_test_df.drop(PROTEIN_NAMES)"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"894a0327922f4137b5c45b5f4e59519f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["datamodule.local_test_df = local_test_df\n","local_test_dataloader = datamodule.local_test_dataloader(local_test_df)\n","\n","for model_path in model_paths:\n","    print(model_path)\n","    modelmodule = LBModelModule.load_from_checkpoint(\n","        checkpoint_path=model_path,\n","        model_name=model_name,\n","    )\n","    local_predictions = trainer.predict(modelmodule, local_test_dataloader)\n","    local_predictions = torch.cat(local_predictions).numpy()\n","    local_pred_dfs = []\n","    for i, protein_name in enumerate(PROTEIN_NAMES):\n","        local_pred_dfs.append(\n","            local_test_df.with_columns(\n","                pl.lit(protein_name).alias(\"protein_name\"),\n","                pl.lit(local_predictions[:, i]).alias(\"binds\"),\n","            )\n","        )\n","    local_pred_df = pl.concat(local_pred_dfs)\n","    local_submit_df = (\n","        local_test_df\n","        .select([\"id\", \"molecule_smiles\", \"protein_name\"])\n","        .join(local_pred_df, on=[\"molecule_smiles\", \"protein_name\"], how=\"left\")\n","        .select([\"id\", \"binds\"])\n","        .sort(\"id\")\n","    )\n","    local_submit_df.write_csv(Path(working_dir, f\"local_submission_{model_path.stem}.csv\"))\n"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11c6599e0f8d4fa8a21e9079a087bd22","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from sklearn.metrics import average_precision_score\n","\n","# ローカルテストデータに対する推論の実行と結果データフレームの作成\n","def infer_and_calculate_ap(local_test_df, model_paths, datamodule, trainer, model_name, PROTEIN_NAMES):\n","    local_test_dataloader = datamodule.local_test_dataloader(local_test_df)\n","    results = []\n","\n","    for model_path in model_paths:\n","        print(model_path)\n","        modelmodule = LBModelModule.load_from_checkpoint(\n","            checkpoint_path=model_path,\n","            model_name=model_name,\n","        )\n","        local_predictions = trainer.predict(modelmodule, local_test_dataloader)\n","        local_predictions = torch.cat(local_predictions).numpy()\n","        local_pred_dfs = []\n","        for i, protein_name in enumerate(PROTEIN_NAMES):\n","            local_pred_dfs.append(\n","                local_test_df.with_columns(\n","                    pl.lit(protein_name).alias(\"protein_name\"),\n","                    pl.lit(local_predictions[:, i]).alias(\"predicted_binds\"),\n","                )\n","            )\n","        local_pred_df = pl.concat(local_pred_dfs)\n","        local_submit_df = (\n","            local_test_df\n","            .select([\"id\", \"molecule_smiles\", \"protein_name\", \"binds\"])\n","            .join(local_pred_df, on=[\"molecule_smiles\", \"protein_name\"], how=\"left\")\n","            .select([\"id\", \"molecule_smiles\", \"protein_name\", \"binds\", \"predicted_binds\"])\n","            .sort(\"id\")\n","        )\n","        results.append(local_submit_df)\n","\n","    return results\n","\n","# 平均適合率スコアの計算\n","def calculate_average_precision(local_submit_df, PROTEIN_NAMES):\n","    average_precision_scores = {}\n","    for protein_name in PROTEIN_NAMES:\n","        y_true = local_submit_df.filter(pl.col(\"protein_name\") == protein_name)[\"binds\"].to_numpy()\n","        y_scores = local_submit_df.filter(pl.col(\"protein_name\") == protein_name)[\"predicted_binds\"].to_numpy()\n","        average_precision_scores[protein_name] = average_precision_score(y_true, y_scores)\n","\n","    return average_precision_scores\n","\n","# 推論の実行とAPスコアの計算\n","results = infer_and_calculate_ap(local_test_df, model_paths, datamodule, trainer, model_name, PROTEIN_NAMES)\n","\n","for i, result in enumerate(results):\n","    print(f\"Results for model {i+1}:\")\n","    print(result)\n","\n","    # APスコアの計算\n","    ap_scores = calculate_average_precision(result, PROTEIN_NAMES)\n","    for protein_name, ap_score in ap_scores.items():\n","        print(f\"Average Precision Score for {protein_name}: {ap_score:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Ensemble"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:26:50.405668Z","iopub.status.busy":"2024-04-23T04:26:50.40536Z","iopub.status.idle":"2024-04-23T04:26:50.412173Z","shell.execute_reply":"2024-04-23T04:26:50.411351Z","shell.execute_reply.started":"2024-04-23T04:26:50.405642Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[PosixPath('../models/submission_model-val_map=0.0946.csv')]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["sub_files = list(working_dir.glob(\"submission_*.csv\"))\n","sub_files"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:26:50.41351Z","iopub.status.busy":"2024-04-23T04:26:50.413174Z","iopub.status.idle":"2024-04-23T04:26:50.72929Z","shell.execute_reply":"2024-04-23T04:26:50.728447Z","shell.execute_reply.started":"2024-04-23T04:26:50.413475Z"},"trusted":true},"outputs":[],"source":["sub_dfs = []\n","for sub_file in sub_files:\n","    sub_dfs.append(pl.read_csv(sub_file))\n","submit_df = (\n","    pl.concat(sub_dfs)\n","    .group_by(\"id\")\n","    .agg(pl.col(\"binds\").mean())\n","    .sort(\"id\")\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T04:27:00.384685Z","iopub.status.busy":"2024-04-23T04:27:00.383862Z","iopub.status.idle":"2024-04-23T04:27:00.45637Z","shell.execute_reply":"2024-04-23T04:27:00.455474Z","shell.execute_reply.started":"2024-04-23T04:27:00.384642Z"},"trusted":true},"outputs":[],"source":["submit_df.write_csv(Path(OUTPUT_DIR, \"submission.csv\"))"]},{"cell_type":"markdown","metadata":{},"source":["## Future Directions\n","- Finding the optimal CV strategy\n","- Increase data\n","- Utilize buildingblock1 ~ buildingblock3\n","- Large-scale models\n","- Tune hyper-parameters\n","- Ensemble\n","- etc..."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8006601,"sourceId":67356,"sourceType":"competition"},{"datasetId":4608382,"sourceId":7856946,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
