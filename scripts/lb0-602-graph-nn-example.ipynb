{"cells":[{"cell_type":"markdown","metadata":{},"source":["for details, refer to https://www.kaggle.com/competitions/leash-BELKA/discussion/498858"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-11T16:08:01.427288Z","iopub.status.busy":"2024-05-11T16:08:01.425787Z","iopub.status.idle":"2024-05-11T16:08:01.435928Z","shell.execute_reply":"2024-05-11T16:08:01.43484Z","shell.execute_reply.started":"2024-05-11T16:08:01.427226Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["import ok!\n"]}],"source":["import numpy as np\n","\n","import rdkit\n","from rdkit import Chem\n","import os\n","import torch\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader\n","import pandas as pd\n","from torch_geometric.nn import MessagePassing, global_mean_pool\n","from torch_scatter import scatter\n","import polars as pl\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.metrics import average_precision_score as APS\n","import pickle\n","import gzip\n","from multiprocessing import Pool\n","\n","print('import ok!')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'__module__': '__main__', 'PREPROCESS': False, 'KAGGLE_NOTEBOOK': False, 'DEBUG': True, 'SEED': 42, 'EPOCHS': 4, 'BATCH_SIZE': 4096, 'LR': 0.001, 'WD': 0.0, 'PATIENCE': 10, 'DEVICE': 'cuda', 'NBR_FOLDS': 15, 'SELECTED_FOLDS': [0], 'EARLY_STOPPING': False, '__dict__': <attribute '__dict__' of 'Config' objects>, '__weakref__': <attribute '__weakref__' of 'Config' objects>, '__doc__': None} 30000\n"]}],"source":["\n","\n","class Config:\n","    PREPROCESS = False\n","    KAGGLE_NOTEBOOK = False\n","    DEBUG = True\n","    \n","    SEED = 42\n","    EPOCHS = \n","    BATCH_SIZE = 4096\n","    LR = 1e-3\n","    WD = 1e-6*0\n","    PATIENCE = 10\n","    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    NBR_FOLDS = 15\n","    SELECTED_FOLDS = [0]\n","    EARLY_STOPPING = False\n","    \n","    \n","if Config.DEBUG:\n","    n_rows = 10**4*3\n","else:\n","    n_rows = None\n","    \n","print(Config.__dict__, n_rows)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["if Config.KAGGLE_NOTEBOOK:\n","    RAW_DIR = \"/kaggle/input/leash-BELKA/\"\n","    PROCESSED_DIR = \"/kaggle/input/belka-enc-dataset\"\n","    OUTPUT_DIR = \"\"\n","    MODEL_DIR = \"\"\n","else:\n","    RAW_DIR = \"../data/raw/\"\n","    PROCESSED_DIR = \"../data/processed/\"\n","    OUTPUT_DIR = \"../data/result/\"\n","    MODEL_DIR = \"../models/\"\n","\n","TRAIN_DATA_NAME = \"train_enc.parquet\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T16:08:01.438686Z","iopub.status.busy":"2024-05-11T16:08:01.437878Z","iopub.status.idle":"2024-05-11T16:08:01.467314Z","shell.execute_reply":"2024-05-11T16:08:01.464879Z","shell.execute_reply.started":"2024-05-11T16:08:01.438647Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["helper ok!\n"]}],"source":["# helper\n","# torch version of np unpackbits\n","#https://gist.github.com/vadimkantorov/30ea6d278bc492abf6ad328c6965613a\n","\n","def tensor_dim_slice(tensor, dim, dim_slice):\n","\treturn tensor[(dim if dim >= 0 else dim + tensor.dim()) * (slice(None),) + (dim_slice,)]\n","\n","# @torch.jit.script\n","def packshape(shape, dim: int = -1, mask: int = 0b00000001, dtype=torch.uint8, pack=True):\n","\tdim = dim if dim >= 0 else dim + len(shape)\n","\tbits, nibble = (\n","\t\t8 if dtype is torch.uint8 else 16 if dtype is torch.int16 else 32 if dtype is torch.int32 else 64 if dtype is torch.int64 else 0), (\n","\t\t1 if mask == 0b00000001 else 2 if mask == 0b00000011 else 4 if mask == 0b00001111 else 8 if mask == 0b11111111 else 0)\n","\t# bits = torch.iinfo(dtype).bits # does not JIT compile\n","\tassert nibble <= bits and bits % nibble == 0\n","\tnibbles = bits // nibble\n","\tshape = (shape[:dim] + (int(math.ceil(shape[dim] / nibbles)),) + shape[1 + dim:]) if pack else (\n","\t\t\t\tshape[:dim] + (shape[dim] * nibbles,) + shape[1 + dim:])\n","\treturn shape, nibbles, nibble\n","\n","# @torch.jit.script\n","def F_unpackbits(tensor, dim: int = -1, mask: int = 0b00000001, shape=None, out=None, dtype=torch.uint8):\n","\tdim = dim if dim >= 0 else dim + tensor.dim()\n","\tshape_, nibbles, nibble = packshape(tensor.shape, dim=dim, mask=mask, dtype=tensor.dtype, pack=False)\n","\tshape = shape if shape is not None else shape_\n","\tout = out if out is not None else torch.empty(shape, device=tensor.device, dtype=dtype)\n","\tassert out.shape == shape\n","\n","\tif shape[dim] % nibbles == 0:\n","\t\tshift = torch.arange((nibbles - 1) * nibble, -1, -nibble, dtype=torch.uint8, device=tensor.device)\n","\t\tshift = shift.view(nibbles, *((1,) * (tensor.dim() - dim - 1)))\n","\t\treturn torch.bitwise_and((tensor.unsqueeze(1 + dim) >> shift).view_as(out), mask, out=out)\n","\n","\telse:\n","\t\tfor i in range(nibbles):\n","\t\t\tshift = nibble * i\n","\t\t\tsliced_output = tensor_dim_slice(out, dim, slice(i, None, nibbles))\n","\t\t\tsliced_input = tensor.narrow(dim, 0, sliced_output.shape[dim])\n","\t\t\ttorch.bitwise_and(sliced_input >> shift, mask, out=sliced_output)\n","\treturn out\n","\n","class dotdict(dict):\n","\t__setattr__ = dict.__setitem__\n","\t__delattr__ = dict.__delitem__\n","\t\n","\tdef __getattr__(self, name):\n","\t\ttry:\n","\t\t\treturn self[name]\n","\t\texcept KeyError:\n","\t\t\traise AttributeError(name)\n","\n","            \n","print('helper ok!')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T16:08:01.569366Z","iopub.status.busy":"2024-05-11T16:08:01.568872Z","iopub.status.idle":"2024-05-11T16:08:01.604085Z","shell.execute_reply":"2024-05-11T16:08:01.60246Z","shell.execute_reply.started":"2024-05-11T16:08:01.56933Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Data(x=[37, 9], edge_index=[2, 78], edge_attr=[78, 1], idx=-1)\n","[Dy] is replaced by C !!\n","smile_to_graph() ok!\n"]}],"source":["# mol to graph adopted from\n","# from https://github.com/LiZhang30/GPCNDTA/blob/main/utils/DrugGraph.py\n","\n","PACK_NODE_DIM=9\n","PACK_EDGE_DIM=1\n","NODE_DIM=PACK_NODE_DIM*8\n","EDGE_DIM=PACK_EDGE_DIM*8\n","\n","def one_of_k_encoding(x, allowable_set, allow_unk=False):\n","\tif x not in allowable_set:\n","\t\tif allow_unk:\n","\t\t\tx = allowable_set[-1]\n","\t\telse:\n","\t\t\traise Exception(f'input {x} not in allowable set{allowable_set}!!!')\n","\treturn list(map(lambda s: x == s, allowable_set))\n","\n","\n","#Get features of an atom (one-hot encoding:)\n","'''\n","\t1.atom element: 44+1 dimensions    \n","\t2.the atom's hybridization: 5 dimensions\n","\t3.degree of atom: 6 dimensions                        \n","\t4.total number of H bound to atom: 6 dimensions\n","\t5.number of implicit H bound to atom: 6 dimensions    \n","\t6.whether the atom is on ring: 1 dimension\n","\t7.whether the atom is aromatic: 1 dimension           \n","\tTotal: 70 dimensions\n","'''\n","\n","ATOM_SYMBOL = [\n","\t'C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg',\n","\t'Na', 'Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl',\n","\t'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H',\n","\t'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr',\n","\t'Pt', 'Hg', 'Pb', 'Dy',\n","\t#'Unknown'\n","]\n","#print('ATOM_SYMBOL', len(ATOM_SYMBOL))44\n","HYBRIDIZATION_TYPE = [\n","\tChem.rdchem.HybridizationType.S,\n","\tChem.rdchem.HybridizationType.SP,\n","\tChem.rdchem.HybridizationType.SP2,\n","\tChem.rdchem.HybridizationType.SP3,\n","\tChem.rdchem.HybridizationType.SP3D\n","]\n","\n","def get_atom_feature(atom):\n","\tfeature = (\n","\t\t one_of_k_encoding(atom.GetSymbol(), ATOM_SYMBOL)\n","\t   + one_of_k_encoding(atom.GetHybridization(), HYBRIDIZATION_TYPE)\n","\t   + one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5])\n","\t   + one_of_k_encoding(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5])\n","\t   + one_of_k_encoding(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5])\n","\t   + [atom.IsInRing()]\n","\t   + [atom.GetIsAromatic()]\n","\t)\n","\t#feature = np.array(feature, dtype=np.uint8)\n","\tfeature = np.packbits(feature)\n","\treturn feature\n","\n","\n","#Get features of an edge (one-hot encoding)\n","'''\n","\t1.single/double/triple/aromatic: 4 dimensions       \n","\t2.the atom's hybridization: 1 dimensions\n","\t3.whether the bond is on ring: 1 dimension          \n","\tTotal: 6 dimensions\n","'''\n","\n","def get_bond_feature(bond):\n","\tbond_type = bond.GetBondType()\n","\tfeature = [\n","\t\tbond_type == Chem.rdchem.BondType.SINGLE,\n","\t\tbond_type == Chem.rdchem.BondType.DOUBLE,\n","\t\tbond_type == Chem.rdchem.BondType.TRIPLE,\n","\t\tbond_type == Chem.rdchem.BondType.AROMATIC,\n","\t\tbond.GetIsConjugated(),\n","\t\tbond.IsInRing()\n","\t]\n","\t#feature = np.array(feature, dtype=np.uint8)\n","\tfeature = np.packbits(feature)\n","\treturn feature\n","\n","\n","def smile_to_graph(smiles):\n","\tmol = Chem.MolFromSmiles(smiles)\n","\tN = mol.GetNumAtoms()\n","\tnode_feature = []\n","\tedge_feature = []\n","\tedge = []\n","\tfor i in range(mol.GetNumAtoms()):\n","\t\tatom_i = mol.GetAtomWithIdx(i)\n","\t\tatom_i_features = get_atom_feature(atom_i)\n","\t\tnode_feature.append(atom_i_features)\n","\n","\t\tfor j in range(mol.GetNumAtoms()):\n","\t\t\tbond_ij = mol.GetBondBetweenAtoms(i, j)\n","\t\t\tif bond_ij is not None:\n","\t\t\t\tedge.append([i, j])\n","\t\t\t\tbond_features_ij = get_bond_feature(bond_ij)\n","\t\t\t\tedge_feature.append(bond_features_ij)\n","\tnode_feature=np.stack(node_feature)\n","\tedge_feature=np.stack(edge_feature)\n","\tedge = np.array(edge,dtype=np.uint8)\n","\treturn N,edge,node_feature,edge_feature\n","\n","def to_pyg_format(N,edge,node_feature,edge_feature):\n","\tgraph = Data(\n","\t\tidx=-1,\n","\t\tedge_index = torch.from_numpy(edge.T).int(),\n","\t\tx          = torch.from_numpy(node_feature).byte(),\n","\t\tedge_attr  = torch.from_numpy(edge_feature).byte(),\n","\t)\n","\treturn graph\n","\n","#debug one example\n","g = to_pyg_format(*smile_to_graph(smiles=\"C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)NC)n2)cc1\"))\n","print(g)\n","print('[Dy] is replaced by C !!')\n","print('smile_to_graph() ok!')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T16:08:01.606965Z","iopub.status.busy":"2024-05-11T16:08:01.606222Z","iopub.status.idle":"2024-05-11T16:08:01.712101Z","shell.execute_reply":"2024-05-11T16:08:01.710764Z","shell.execute_reply.started":"2024-05-11T16:08:01.6069Z"},"trusted":true},"outputs":[],"source":["import json\n","\n","from multiprocessing import Pool\n","from tqdm import tqdm\n","import gc\n","from torch_geometric.loader import DataLoader as PyGDataLoader\n","\n","def to_pyg_list(graph):\n","\tL = len(graph)\n","\tfor i in tqdm(range(L)):\n","\t\tN, edge, node_feature, edge_feature = graph[i]\n","\t\tgraph[i] = Data(\n","\t\t\tidx=i,\n","\t\t\tedge_index=torch.from_numpy(edge.T).int(),\n","\t\t\tx=torch.from_numpy(node_feature).byte(),\n","\t\t\tedge_attr=torch.from_numpy(edge_feature).byte(),\n","\t\t)\n","\treturn graph\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch_geometric.data import Data\n","import json\n","\n","def save_data_to_parquet(data_list, bind_data, file_name):\n","    data_dicts = []\n","    for data in data_list:\n","        data_dict = {\n","            'x': data.x.numpy().tolist(),\n","            'edge_index': data.edge_index.numpy().tolist(),\n","            'edge_attr': data.edge_attr.numpy().tolist() if data.edge_attr is not None else None,\n","            'idx': data.idx\n","        }\n","        data_dicts.append(data_dict)\n","    graph_df = pd.DataFrame(data_dicts)\n","    \n","    combined_df = pd.concat([graph_df, bind_data], axis=1)\n","    combined_df = pl.DataFrame(combined_df)\n","    combined_df.write_parquet(file_name)\n","\n","def load_data_from_parquet(file_name):\n","    combined_df = pl.read_parquet(file_name)\n","    \n","    data_list = [\n","        Data(\n","            idx=row['idx'],\n","            edge_index=torch.from_numpy(np.array(row['edge_index'], dtype=np.int32)).int(),\n","            x=torch.from_numpy(np.array(row['x'], dtype=np.uint8)).byte(),\n","            edge_attr=torch.from_numpy(np.array(row['edge_attr'], dtype=np.uint8)).byte() if row['edge_attr'] is not None else None,\n","        )\n","        for row in combined_df.to_dicts()\n","    ]\n","    bind_data = combined_df.select(['bind1', 'bind2', 'bind3']).to_pandas()\n","    \n","    return data_list, bind_data"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["data loaded ../data/shuffled-dataset/train_0.parquet (1000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 5579.33it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 31291.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["data saved ../data/graph/train_graph_0.parquet 1000\n","data loaded ../data/shuffled-dataset/train_1.parquet (1000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 3764.43it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 31525.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["data saved ../data/graph/train_graph_1.parquet 1000\n","data loaded ../data/shuffled-dataset/train_2.parquet (1000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 6473.59it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 4502.72it/s]"]},{"name":"stdout","output_type":"stream","text":["data saved ../data/graph/train_graph_2.parquet 1000\n","data loaded ../data/shuffled-dataset/train_3.parquet (1000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 1000/1000 [00:00<00:00, 4663.16it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 29402.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["data saved ../data/graph/train_graph_3.parquet 1000\n","data loaded ../data/shuffled-dataset/train_4.parquet (1000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 6261.77it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 27405.33it/s]"]},{"name":"stdout","output_type":"stream","text":["data saved ../data/graph/train_graph_4.parquet 1000\n","data loaded ../data/shuffled-dataset/train_5.parquet (1000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 1000/1000 [00:00<00:00, 5911.13it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 29759.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["data saved ../data/graph/train_graph_5.parquet 1000\n","data loaded ../data/shuffled-dataset/train_6.parquet (1000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 4622.69it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 28711.39it/s]"]},{"name":"stdout","output_type":"stream","text":["data saved ../data/graph/train_graph_6.parquet 1000\n","data loaded ../data/shuffled-dataset/train_7.parquet (1000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 1000/1000 [00:00<00:00, 4158.97it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 29356.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["data saved ../data/graph/train_graph_7.parquet 1000\n","data loaded ../data/shuffled-dataset/train_8.parquet (1000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 4819.86it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 29878.85it/s]\n"]},{"name":"stdout","output_type":"stream","text":["data saved ../data/graph/train_graph_8.parquet 1000\n","data loaded ../data/shuffled-dataset/train_9.parquet (1000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 5361.87it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 28875.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["data saved ../data/graph/train_graph_9.parquet 1000\n"]}],"source":["n_rows = 10**3\n","INPUT_DIR = \"../data/shuffled-dataset/\"\n","SAVE_PATH = \"../data/graph/\"\n","for i in range(10):\n","    input_path = os.path.join(INPUT_DIR, f\"train_{i}.parquet\")\n","    train = pl.read_parquet(input_path, n_rows=n_rows, columns=[\"molecule_smiles\"]).to_pandas()\n","    print(\"data loaded\", input_path, train.shape)\n","\n","    # グラフに変換\n","    train_smiles=train['molecule_smiles'].values\n","    num_train= len(train_smiles)\n","    with Pool(processes=64) as pool:\n","        train_graph = list(tqdm(pool.imap(smile_to_graph, train_smiles), total=num_train))\n","    train_graph = to_pyg_list(train_graph)\n","    output_path = os.path.join(SAVE_PATH, f\"train_graph_{i}.parquet\")\n","    torch.save(train_graph, output_path)\n","    print(\"data saved\", output_path, len(train_graph))\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["graph = torch.load(os.path.join(\"../data/graph-dataset/\", f\"train_graph_{0}.parquet\"))\n","\n","# 1e6 1min40s"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["data loaded ../data/shuffled-dataset/train_0.parquet (1000000, 1)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000000/1000000 [03:32<00:00, 4713.59it/s]\n","100%|██████████| 1000000/1000000 [00:46<00:00, 21486.13it/s]\n"]}],"source":["n_rows = 10**6\n","INPUT_DIR = \"../data/shuffled-dataset/\"\n","SAVE_PATH = \"../data/graph/\"\n","i = 0\n","input_path = os.path.join(INPUT_DIR, f\"train_{i}.parquet\")\n","train = pl.read_parquet(input_path, n_rows=n_rows, columns=[\"molecule_smiles\"]).to_pandas()\n","print(\"data loaded\", input_path, train.shape)\n","\n","# グラフに変換\n","train_smiles=train['molecule_smiles'].values\n","num_train= len(train_smiles)\n","with Pool(processes=64) as pool:\n","    train_graph = list(tqdm(pool.imap(smile_to_graph, train_smiles), total=num_train))\n","train_graph = to_pyg_list(train_graph)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import indexed_bzip2 as ibz2\n","\n","\n","\n","def load_compressed_ibz2_pickle(file):\n","    with ibz2.open(file, parallelization=os.cpu_count()) as f:\n","        data = cPickle.load(f)\n","    return data"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# indexed_bzip2を使ってデータを保存する関数\n","def save_compressed_ibz2_pickle(data, file_path):\n","    # indexed_bzip2を用いてファイルを書き込みモードで開く\n","    # CPUのコア数をparallelizationに指定して圧縮処理の高速化\n","    with ibz2.open(file_path,  parallelization=os.cpu_count()) as f:\n","        pickle.dump(data, f)\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["import _pickle as  cPickle\n","import bz2\n","def save_compressed_pickle(file, data):\n","    with bz2.BZ2File(file , 'w') as f:\n","        cPickle.dump(data, f)\n","\n","def load_decompress_pickle(file):\n","    data = bz2.BZ2File(file, 'rb')\n","    data = cPickle.load(data)\n","    return data\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["train_graph = torch.load(os.path.join(\"../data/graph-dataset/\", f\"train_graph_{0}.parquet\"))"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["save_compressed_pickle(os.path.join(SAVE_PATH, f\"train_graph_{i}_big.pbz2\"), train_graph)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["graph = load_compressed_ibz2_pickle(os.path.join(SAVE_PATH, f\"train_graph_{i}_big.pbz2\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pickleのバイナリで保存 no zip\n","with open(os.path.join(SAVE_PATH, f\"train_graph_{i}.pickle\"), 'wb') as f:\n","    pickle.dump(train_graph, f, protocol=pickle.HIGHEST_PROTOCOL)\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# pickle　ロード\n","with open(os.path.join(SAVE_PATH, f\"train_graph_{i}.pickle\"), 'rb') as f:\n","    train_graph = pickle.load(f)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["SAVE_PATH = \"../data/graph/\"\n","graph, binds = load_data_from_parquet(os.path.join(SAVE_PATH, f\"train_graph_{i}.parquet\"))\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["train_graph = graph\n","train_bind = binds.to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(100000, (100000, 3))"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# load data\n","train_graph, binds = load_data_from_parquet(os.path.join(SAVE_PATH, f\"train_graph_{i}.parquet\"))\n","train_bind = binds.to_numpy()\n","\n","len(train_graph), train_bind.shape"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["model ok!\n"]}],"source":["#MODEL: simple MPNNModel\n","#from https://github.com/chaitjo/geometric-gnn-dojo/blob/main/geometric_gnn_101.ipynb\n","\n","DEVICE='cpu'\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# i have removed all comments here to jepp it clean. refer to orginal link for code comments\n","# of MPNNModel\n","class MPNNLayer(MessagePassing):\n","\tdef __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n","\t\tsuper().__init__(aggr=aggr)\n","\n","\t\tself.emb_dim = emb_dim\n","\t\tself.edge_dim = edge_dim\n","\t\tself.mlp_msg = nn.Sequential(\n","\t\t\tnn.Linear(2 * emb_dim + edge_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(),\n","\t\t\tnn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU()\n","\t\t)\n","\t\tself.mlp_upd = nn.Sequential(\n","\t\t\tnn.Linear(2 * emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(),\n","\t\t\tnn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU()\n","\t\t)\n","\n","\tdef forward(self, h, edge_index, edge_attr):\n","\t\tout = self.propagate(edge_index, h=h, edge_attr=edge_attr)\n","\t\treturn out\n","\n","\tdef message(self, h_i, h_j, edge_attr):\n","\t\tmsg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n","\t\treturn self.mlp_msg(msg)\n","\n","\tdef aggregate(self, inputs, index):\n","\t\treturn scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n","\n","\tdef update(self, aggr_out, h):\n","\t\tupd_out = torch.cat([h, aggr_out], dim=-1)\n","\t\treturn self.mlp_upd(upd_out)\n","\n","\tdef __repr__(self) -> str:\n","\t\treturn (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n","\n","\n","class MPNNModel(nn.Module):\n","\tdef __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n","\t\tsuper().__init__()\n","\n","\t\tself.lin_in = nn.Linear(in_dim, emb_dim)\n","\n","\t\t# Stack of MPNN layers\n","\t\tself.convs = torch.nn.ModuleList()\n","\t\tfor layer in range(num_layers):\n","\t\t\tself.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n","\n","\t\tself.pool = global_mean_pool\n","\n","\tdef forward(self, data): #PyG.Data - batch of PyG graphs\n","\n","\t\th = self.lin_in(F_unpackbits(data.x,-1).float())  \n","\n","\t\tfor conv in self.convs:\n","\t\t\th = h + conv(h, data.edge_index.long(), F_unpackbits(data.edge_attr,-1).float())  # (n, d) -> (n, d)\n","\n","\t\th_graph = self.pool(h, data.batch)  \n","\t\treturn h_graph\n","\n","# our prediction model here !!!!\n","class Net(nn.Module):\n","\tdef __init__(self, ):\n","\t\tsuper().__init__()\n","\n","\t\tself.output_type = ['infer', 'loss']\n","\n","\t\tgraph_dim=96\n","\t\tself.smile_encoder = MPNNModel(\n","\t\t\t in_dim=NODE_DIM, edge_dim=EDGE_DIM, emb_dim=graph_dim, num_layers=4,\n","\t\t)\n","\t\tself.bind = nn.Sequential(\n","\t\t\tnn.Linear(graph_dim, 1024),\n","\t\t\t#nn.BatchNorm1d(1024),\n","\t\t\tnn.ReLU(inplace=True),\n","\t\t\tnn.Dropout(0.1),\n","\t\t\tnn.Linear(1024, 1024),\n","\t\t\t#nn.BatchNorm1d(1024),\n","\t\t\tnn.ReLU(inplace=True),\n","\t\t\tnn.Dropout(0.1),\n","\t\t\tnn.Linear(1024, 512),\n","\t\t\t#nn.BatchNorm1d(512),\n","\t\t\tnn.ReLU(inplace=True),\n","\t\t\tnn.Dropout(0.1),\n","\t\t\tnn.Linear(512, 3),\n","\t\t)\n","\n","\tdef forward(self, batch):\n","\t\tgraph = batch['graph']\n","\t\tx = self.smile_encoder(graph) \n","\t\tbind = self.bind(x)\n","\n","\t\t# --------------------------\n","\t\toutput = {}\n","\t\tif 'loss' in self.output_type:\n","\t\t\ttarget = batch['bind']\n","\t\t\toutput['bce_loss'] = F.binary_cross_entropy_with_logits(bind.float(), target.float())\n","\t\tif 'infer' in self.output_type:\n","\t\t\toutput['bind'] = torch.sigmoid(bind)\n","\n","\t\treturn output\n","    \n","#debug: make some dummy data and run\n","\n","def run_check_net():\n","\tbatch_size = 3\n","\tnode_dim=NODE_DIM\n","\tedge_dim=EDGE_DIM\n","\n","\tdata = []\n","\tfor b in range(batch_size):\n","\t\tN = np.random.randint(5,10)\n","\t\tE = np.random.randint(3,N*(N-1))\n","\t\tedge_index = np.stack([\n","\t\t\tnp.random.choice(N, E, replace=True),\n","\t\t\tnp.random.choice(N, E, replace=True),\n","\t\t]).T\n","\t\tedge_index = np.sort(edge_index)\n","\t\tedge_index = edge_index[edge_index[:, 0].argsort()]\n","\t\tedge_index[0] = [0,1] #default\n","\t\tedge_index = edge_index[edge_index[:,0]!=edge_index[:,1]]\n","\t\tedge_index = np.unique(edge_index, axis=0)\n","\n","\t\tE = len(edge_index)\n","\t\tedge_index = np.ascontiguousarray(edge_index.T)\n","\n","\t\td = Data(\n","\t\t\tidx        = b,\n","\t\t\tedge_index = torch.from_numpy(edge_index).int(),\n","\t\t\tx          = torch.from_numpy(np.packbits(np.random.choice(2, (N, node_dim)),-1)).byte(),\n","\t\t\tedge_attr  = torch.from_numpy(np.packbits(np.random.choice(2, (E, edge_dim)),-1)).byte(),\n","\t\t)\n","\t\tdata.append(d)\n","\n","\t#from my_mol2graph import make_dummy_data\n","\t#data = make_dummy_data()\n","\n","\tloader = DataLoader(data, batch_size=batch_size)\n","\tgraph = next(iter(loader))\n","\tidx = graph.idx.tolist()  #use to index bind array\n","\tbatch = dotdict( \n","\t\tgraph = graph.to(DEVICE),\n","\t\tbind  = torch.from_numpy(np.random.choice(2, (batch_size, 3))).float().to(DEVICE),\n","\t)\n","\tzz=0\n"," \n","\tnet = Net().to(DEVICE)\n","\t#print(net)\n","\n","\twith torch.no_grad():\n","\t\twith torch.cuda.amp.autocast(enabled=True): # dtype=torch.float16):\n","\t\t\toutput = net(batch)\n","\t\t\t#print(output['bind'])\n","\n","\t# ---\n","\tprint('batch')\n","\tfor k, v in batch.items():\n","\t\tif k=='idx':\n","\t\t\tprint(f'{k:>32} : {len(v)} ')\n","\t\telif k=='graph':\n","\t\t\tprint(f'{k:>32} : {graph} ')\n","\t\telse:\n","\t\t\tprint(f'{k:>32} : {v.shape} ')\n","\n","\tprint('output')\n","\tfor k, v in output.items():\n","\t\tif 'loss' not in k:\n","\t\t\tprint(f'{k:>32} : {v.shape} ')\n","\tprint('loss')\n","\tfor k, v in output.items():\n","\t\tif 'loss' in k:\n","\t\t\tprint(f'{k:>32} : {v.item()} ')\n","\n","            \n","# run_check_net()\n","print('model ok!')"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T16:08:01.717077Z","iopub.status.busy":"2024-05-11T16:08:01.716159Z","iopub.status.idle":"2024-05-11T16:08:04.32686Z","shell.execute_reply":"2024-05-11T16:08:04.325228Z","shell.execute_reply.started":"2024-05-11T16:08:01.717028Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0 0.04708818061163231\n"]}],"source":["train_loader = PyGDataLoader(train_graph, batch_size=1024, shuffle=False)\n","NODE_DIM = 72\n","EDGE_DIM = 8\n","\n","## example training loop\n","scaler = torch.cuda.amp.GradScaler(enabled=True)\n","net = Net()\n","net.to(DEVICE)\n","\n","optimizer =\\\n","\ttorch.optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001)\n","\n","num_epoch=1\n","for epoch in range(num_epoch):\n","\tloss = 0\n","\tfor t, graph_batch in enumerate(train_loader): \n","\t\tindex = graph_batch.idx.tolist()\n","\t\tB = len(index)\n","\t\tbatch = dotdict(\n","\t\t\tgraph  = graph_batch.to(DEVICE),\n","\t\t\tbind   = torch.from_numpy(train_bind[index]).to(DEVICE),\n","\t\t)\n","\t\tnet.train()\n","\t\tnet.output_type = ['loss', 'infer']\n","\t\twith torch.cuda.amp.autocast(enabled=True):\n","\t\t\toutput = net(batch)  #data_parallel(net,batch) #\n","\t\t\tbce_loss = output['bce_loss']\n","\n","\t\toptimizer.zero_grad() \n","\t\tscaler.scale(bce_loss).backward() \n","\t\tscaler.step(optimizer)\n","\t\tscaler.update()\n","\t\t\t\n","\t\ttorch.clear_autocast_cache()\n","\t\tloss += bce_loss.item()\n","\tprint(epoch, loss/(t+1))\n","        \n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.00463001, 0.00498012, 0.00799094],\n","       [0.00187701, 0.00207349, 0.0033317 ],\n","       [0.00099357, 0.00107744, 0.00195775],\n","       ...,\n","       [0.00045838, 0.00054313, 0.00081576],\n","       [0.01150584, 0.01216839, 0.01937337],\n","       [0.00183857, 0.00204131, 0.00326739]], dtype=float32)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# inference\n","net.eval()\n","net.output_type = ['infer']\n","preds = []\n","with torch.no_grad():\n","    for t, graph_batch in enumerate(train_loader): \n","        index = graph_batch.idx.tolist()\n","        B = len(index)\n","        batch = dotdict(\n","            graph  = graph_batch.to(DEVICE),\n","            bind   = torch.from_numpy(train_bind[index]).to(DEVICE),\n","        )\n","        output = net(batch)\n","        preds.append(output['bind'].cpu().numpy())\n","preds = np.concatenate(preds)\n","\n","preds "]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["0.10593622164479431"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["APS(train_bind, preds)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8006601,"sourceId":67356,"sourceType":"competition"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
