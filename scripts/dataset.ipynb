{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    PREPROCESS = False\n",
    "    KAGGLE_NOTEBOOK = False\n",
    "    DEBUG = True\n",
    "    \n",
    "    SEED = 42\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZE = 4096\n",
    "    LR = 1e-3\n",
    "    WD = 0.05\n",
    "    PATIENCE = 5\n",
    "    NBR_FOLDS = 15\n",
    "    SELECTED_FOLDS = [0]\n",
    "    \n",
    "    \n",
    "if Config.DEBUG:\n",
    "    n_rows = 10**3\n",
    "else:\n",
    "    n_rows = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.KAGGLE_NOTEBOOK:\n",
    "    RAW_DIR = \"/kaggle/input/leash-BELKA/\"\n",
    "    PROCESSED_DIR = \"/kaggle/input/belka-enc-dataset\"\n",
    "    OUTPUT_DIR = \"\"\n",
    "    MODEL_DIR = \"\"\n",
    "else:\n",
    "    RAW_DIR = \"../data/raw/\"\n",
    "    PROCESSED_DIR = \"../data/processed/\"\n",
    "    OUTPUT_DIR = \"../data/result/\"\n",
    "    MODEL_DIR = \"../models/\"\n",
    "\n",
    "TRAIN_DATA_NAME = \"local_train_enc.parquet\"\n",
    "SAVE_PATH = \"../data/chuncked-dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを10分割して保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split dataset to several parquet\n",
    "train = pl.read_parquet(os.path.join(PROCESSED_DIR, TRAIN_DATA_NAME), n_rows=None)\n",
    "\n",
    "# shuffle\n",
    "train = train.sample(fraction=1, seed=Config.SEED, shuffle=True)\n",
    "# trainを10分割して保存\n",
    "n = 10\n",
    "chunk_size = len(train) // n\n",
    "for i in range(n):\n",
    "    chunk = train[i*chunk_size:(i+1)*chunk_size]\n",
    "    chunk.write_parquet(os.path.join(SAVE_PATH, f\"local_train_enc_{i}.parquet\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マスクを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [f'enc{i}' for i in range(142)]\n",
    "\n",
    "for i in range(10):\n",
    "    train = pl.read_parquet(os.path.join(SAVE_PATH, f\"local_train_enc_{i}.parquet\"), n_rows=None).to_pandas()\n",
    "    mask_df = (train.values > 0).astype(int)\n",
    "    mask_df = pd.DataFrame(mask_df, columns=train.columns)\n",
    "    mask_df = mask_df[FEATURES]\n",
    "    mask_df.to_parquet(os.path.join(SAVE_PATH, f\"local_train_mask_{i}.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_parquet(os.path.join(SAVE_PATH, f\"local_train_enc_0.parquet\"), n_rows=1000).to_pandas()\n",
    "mask = pl.read_parquet(os.path.join(SAVE_PATH, f\"local_train_mask_0.parquet\"), n_rows=1000).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['enc0', 'enc1', 'enc2', 'enc3', 'enc4', 'enc5', 'enc6', 'enc7', 'enc8',\n",
       "        'enc9', 'enc10', 'enc11', 'enc12', 'enc13', 'enc14', 'enc15', 'enc16',\n",
       "        'enc17', 'enc18', 'enc19', 'enc20', 'enc21', 'enc22', 'enc23', 'enc24',\n",
       "        'enc25', 'enc26', 'enc27', 'enc28', 'enc29', 'enc30', 'enc31', 'enc32',\n",
       "        'enc33', 'enc34', 'enc35', 'enc36', 'enc37', 'enc38', 'enc39', 'enc40',\n",
       "        'enc41', 'enc42', 'enc43', 'enc44', 'enc45', 'enc46', 'enc47', 'enc48',\n",
       "        'enc49', 'enc50', 'enc51', 'enc52', 'enc53', 'enc54', 'enc55', 'enc56',\n",
       "        'enc57', 'enc58', 'enc59', 'enc60', 'enc61', 'enc62', 'enc63', 'enc64',\n",
       "        'enc65', 'enc66', 'enc67', 'enc68', 'enc69', 'enc70', 'enc71', 'enc72',\n",
       "        'enc73', 'enc74', 'enc75', 'enc76', 'enc77', 'enc78', 'enc79'],\n",
       "       dtype='object'),\n",
       " Index(['enc0', 'enc1', 'enc2', 'enc3', 'enc4', 'enc5', 'enc6', 'enc7', 'enc8',\n",
       "        'enc9', 'enc10', 'enc11', 'enc12', 'enc13', 'enc14', 'enc15', 'enc16',\n",
       "        'enc17', 'enc18', 'enc19', 'enc20', 'enc21', 'enc22', 'enc23', 'enc24',\n",
       "        'enc25', 'enc26', 'enc27', 'enc28', 'enc29', 'enc30', 'enc31', 'enc32',\n",
       "        'enc33', 'enc34', 'enc35', 'enc36', 'enc37', 'enc38', 'enc39', 'enc40',\n",
       "        'enc41', 'enc42', 'enc43', 'enc44', 'enc45', 'enc46', 'enc47', 'enc48',\n",
       "        'enc49', 'enc50', 'enc51', 'enc52', 'enc53', 'enc54', 'enc55', 'enc56',\n",
       "        'enc57', 'enc58', 'enc59', 'enc60', 'enc61', 'enc62', 'enc63', 'enc64',\n",
       "        'enc65', 'enc66', 'enc67', 'enc68', 'enc69', 'enc70', 'enc71', 'enc72',\n",
       "        'enc73', 'enc74', 'enc75', 'enc76', 'enc77', 'enc78', 'enc79'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.loc[100][mask.loc[0] == 1].index, train.loc[100][train.loc[0] > 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
